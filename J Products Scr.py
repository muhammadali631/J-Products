# -*- coding: utf-8 -*-
"""J Products Scr (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gx6Pc0PeLSMx3lIUeaARRUXDyVk20xoK
"""

import requests
from bs4 import BeautifulSoup as soup
import csv
import pandas as pd

# source = requests.get("https://www.junaidjamshed.com/mens/kurta-pajama.html")
source = requests.get("https://www.junaidjamshed.com/mens/kameez-shalwar.html")
webpage = soup(source.content,features = "html.parser")

links = webpage.find_all('a', class_="product-item-link")

def extract_name(soup):
    a = soup.find("span", class_="base").text.strip()
    parts = a.split("|")

    if len(parts) >= 1:
        name = parts[0].strip()
    else:
        name = ''

    return name

def extract_product_price(soup):
    price_element = soup.find("span", class_="price")
    if price_element is None:
        return None

    price_text = price_element.text.strip()

    # Remove the currency symbol and comma
    price_text = price_text.replace("PKR", "").replace(",", "")

    try:
        price = float(price_text)
    except ValueError:
        price = None

    return price

def extract_original_price(soup):
    orig_price = soup.find("span", class_="old-price sly-old-price")

    if orig_price is not None:
        original_price_text = orig_price.text.strip()

        try:
            original_price = float(original_price_text.split("PKR")[1].replace(",", ""))
        except (IndexError, ValueError):
            original_price = None
    else:
        original_price = None

    return original_price

def extract_additional_attributes(soup):
    keys = ['Color', 'Wear Type', 'Product Category', 'Collection', 'Fabric', 'Fit Type']

    table = soup.find("table", class_="data table additional-attributes")
    if table is None:
        return {}

    values = []
    for key in keys:
        value = table.find('th', string=key)
        if value is not None:
            value = value.find_next('td').text.strip()
        else:
            value = ""
        values.append(value)

    attributes = dict(zip(keys, values))
    return attributes

#function to extract links to the product
def extract_href_links(result_set):
    links = []
    for link in result_set:
        href = link.get('href')
        links.append(href)
    return links

links = extract_href_links(links)

def extract_all_page_links(soup, current_page_link):
    page_links = []

    # Add the current page link to the list
    page_links.append(current_page_link)

    all_page_links = soup.find_all("a", class_="page")
    for link in all_page_links:
        href = link.get("href")
        page_links.append(href)

    # Add links to remaining pages (pages 6 to 10)
    for page_num in range(6, 11):
        # page_link = f"https://www.junaidjamshed.com/mens/kurta-pajama.html?p={page_num}"
        page_link = f"https://www.junaidjamshed.com/mens/kameez-shalwar.html?p={page_num}"
        page_links.append(page_link)

    return page_links

# all_page_links = extract_all_page_links(webpage,'https://www.junaidjamshed.com/mens/kurta-pajama.html')
all_page_links = extract_all_page_links(webpage,'https://www.junaidjamshed.com/mens/kameez-shalwar.html')
all_page_links

#function to extract links to the product
def extract_href_links(result_set):
    links = []
    for link in result_set:
        href = link.get('href')
        links.append(href)
    return links

import requests
from bs4 import BeautifulSoup as soup
import csv
import pandas as pd

# Create empty lists to store the extracted details
product_names = []
product_prices = []
product_original_prices = []
product_colors = []
product_wear_types = []
product_categories = []
product_collections = []
product_fabrics = []
product_fit_types = []

# Iterate over the page links
for link in all_page_links:
    source = requests.get(link)
    webpage = soup(source.content, features="html.parser")
    linkss = webpage.find_all('a', class_="product-item-link")

    # Extract product details from each link
    # Extract product details from each link
    pro_links = extract_href_links(linkss)

    for link in pro_links:
        if link is None:
            continue

        source = requests.get(link)
        new_soup = soup(source.content, features="html.parser")

        # Extract product name
        name = extract_name(new_soup)
        product_names.append(name)

        # Extract product price
        price = extract_product_price(new_soup)
        product_prices.append(price)

        # Extract original price
        original_price = extract_original_price(new_soup)
        product_original_prices.append(original_price)

        # Extract additional attributes
        attributes = extract_additional_attributes(new_soup)
        product_colors.append(attributes.get('Color', ''))
        product_wear_types.append(attributes.get('Wear Type', ''))
        product_categories.append(attributes.get('Product Category', ''))
        product_collections.append(attributes.get('Collection', ''))
        product_fabrics.append(attributes.get('Fabric', ''))
        product_fit_types.append(attributes.get('Fit Type', ''))


# Create a DataFrame from the extracted details
data = {
    'Name': product_names,
    'Price': product_prices,
    # 'Price': product_original_prices,
    'Color': product_colors,
    'Wear Type': product_wear_types,
    'Product Category': product_categories,
    'Collection': product_collections,
    'Fabric': product_fabrics,
    'Fit Type': product_fit_types
}
df = pd.DataFrame(data)

display(df)

!pip install pandas openpyxl

df.to_excel('output.xlsx', index=False, engine='openpyxl')

"""# New Section"""